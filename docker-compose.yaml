services:
  postgres:
    build:
      context: ./database
    ports:
      - "5432:5432"
    environment:
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
      - POSTGRES_DB=${POSTGRES_DB}
    volumes:
      - ./data/postgres:/var/lib/postgresql/data
      - ./database/init:/docker-entrypoint-initdb.d
      - postgres_data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD", "pg_isready", "-U", "${POSTGRES_USER}"]
      interval: 5s
      retries: 5
    restart: always

  airflow-webserver:
    build:
      context: ./airflow
    command: webserver
    depends_on:
      - postgres
    environment:
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
      - POSTGRES_DB=${POSTGRES_DB}
      - POSTGRES_HOST=postgres
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB}
      - AIRFLOW__CORE__FERNET_KEY=${AIRFLOW__CORE__FERNET_KEY}
      - AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION=${AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION}
      - AIRFLOW__CORE__LOAD_EXAMPLES=${AIRFLOW__CORE__LOAD_EXAMPLES}
      - WILDBERRIES_API_KEY=${WILDBERRIES_API_KEY}
      - OZON_API_KEY=${OZON_API_KEY}
      - OZON_CLIENT_ID=${OZON_CLIENT_ID}
      - DATA_CSV_PATH=${DATA_CSV_PATH}
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/plugins:/opt/airflow/plugins
      - ./airflow/config:/opt/airflow/config
      - ./data/logs/airflow:/opt/airflow/logs
      - ./data/csv:/opt/airflow/data/csv
      - ./data/raw:/opt/airflow/data/raw:rw
    ports:
      - "8080:8080"
    healthcheck:
      test: ["CMD", "curl", "--fail", "http://localhost:8080/health"]
      interval: 10s
      timeout: 10s
      retries: 5
    restart: always

  airflow-scheduler:
    build:
      context: ./airflow
    command: scheduler
    depends_on:
      - postgres
      - airflow-webserver
    environment:
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
      - POSTGRES_DB=${POSTGRES_DB} 
      - POSTGRES_HOST=postgres
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB}
      - AIRFLOW__CORE__FERNET_KEY=${AIRFLOW__CORE__FERNET_KEY}
      - AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION=${AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION}
      - AIRFLOW__CORE__LOAD_EXAMPLES=${AIRFLOW__CORE__LOAD_EXAMPLES}
      - WILDBERRIES_API_KEY=${WILDBERRIES_API_KEY}
      - OZON_API_KEY=${OZON_API_KEY}
      - OZON_CLIENT_ID=${OZON_CLIENT_ID}
      - DATA_CSV_PATH=${DATA_CSV_PATH}
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/plugins:/opt/airflow/plugins
      - ./airflow/config:/opt/airflow/config
      - ./data/logs/airflow:/opt/airflow/logs
      - ./data/csv:/opt/airflow/data/csv
      - ./data/raw:/opt/airflow/data/raw:rw
    restart: always

  backend:
    build:
      context: ./backend
    depends_on:
      - postgres
    environment:
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
      - POSTGRES_DB=${POSTGRES_DB}
      - POSTGRES_HOST=postgres
      - WILDBERRIES_API_KEY=${WILDBERRIES_API_KEY}
      - OZON_API_KEY=${OZON_API_KEY}
      - OZON_CLIENT_ID=${OZON_CLIENT_ID}
    ports:
      - "5000:5000"
    restart: always

  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    depends_on:
      - backend
    ports:
      - "3000:80"
    restart: always

  metabase:
    build: 
      context: ./metabase
    environment:
      - MB_DB_TYPE=postgres
      - MB_DB_DBNAME=${POSTGRES_DB}
      - MB_DB_PORT=5432
      - MB_DB_USER=${POSTGRES_USER}
      - MB_DB_PASS=${POSTGRES_PASSWORD}
      - MB_DB_HOST=postgres
    ports:
      - "3001:3000"
    depends_on:
      - postgres
    restart: always

volumes:
  postgres_data: